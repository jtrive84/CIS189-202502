{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## CIS189 Module \\#14\n",
    "---\n",
    "Author: James D. Triveri\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### **Python Standard Library Quick Hits**\n",
    "\n",
    "In the class, we've worked a bit with the Python standard library, but there are many modules we haven't had a chance to explore. This week, we'll discuss a few that might be useful for various tasks if you end up using Python beyond this class, which you definitely should!\n",
    "\n",
    "The full list of standard library packages is available here: \n",
    "\n",
    "- [Python Module Index](https://docs.python.org/3/py-modindex.html)\n",
    "\n",
    "\n",
    "We will be discussing four libraries:\n",
    "\n",
    "- **pickle**: Serialize Python objects\n",
    "- **hashlib**: Generate hashes \n",
    "- **difflib**: Quantify differences between sequences\n",
    "- **re**: Regular expressions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "### **[1. pickle](https://docs.python.org/3/library/pickle.html#module-pickle)**\n",
    "\n",
    "Python's pickle module is used for serializing and deserializing objects. Serialization, often referred to as \"pickling,\" involves converting a Python object into a byte stream, and deserialization, known as \"unpickling,\" is the inverse operation, converting a byte stream back into a Python object.\n",
    "\n",
    "This allows us to save virtually any Python object (dict, list, tuple, set) to file, which can be read in by other potential users or at some later date into an independent Python session.\n",
    "\n",
    "Reasons to serialize objects:\n",
    "\n",
    "- Saving complicated data types to a file, so that programs can resume where they left off (persistence).\n",
    "- Sending Python data over a TCP/IP connection between processes or machines (data interchange).\n",
    "- Caching or saving state between program executions.\n",
    "\n",
    "<br>\n",
    "\n",
    "In the next cell, we create a list, add elements to it then write it to a pickle file (usually has a .pkl extension):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "# Create an arbitrary list.\n",
    "vals = [\"hey\", \"hey\", \"my\", \"my\"]\n",
    "\n",
    "\n",
    "# Store vals list in a .pkl file in current working directory. \n",
    "with open(\"vals-list.pkl\", \"wb\") as fpkl:\n",
    "    pickle.dump(vals, fpkl, pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "Assume we want to load the `vals` list into a new Python session, or allow someone else to access it. Here's how to load a serialized object back into Python using pickle:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hey', 'hey', 'my', 'my']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with open(\"vals-list.pkl\", \"rb\") as fpkl:\n",
    "    vals = pickle.load(fpkl)\n",
    "\n",
    "vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add more elements to vals, and re-serialize.\n",
    "vals = vals + [\"rock n roll\", \"can\", \"never\", \"die\"]\n",
    "\n",
    "# Serialize updated vals list.\n",
    "with open(\"vals-list.pkl\", \"wb\") as fpkl:\n",
    "    pickle.dump(vals, fpkl, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "### **Checkpoint \\#1**\n",
    "\n",
    "The `daily` list contains date, high temperature, low temperature, time of sunrise and time of sunset for a given week in Des Moines. Create a dictionary `dtemps`, keyed by date, where each key points to a dictionary of items in the list. For example, the first two entries of `dtemps` should look like:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"2024-07-08\": {\"low\": 63, \"high\": 82, \"sunrise\": \"05:48\", \"sunset\": \"20:50\"},\n",
    "    \"2024-07-09\": {\"low\": 67, \"high\": 85, \"sunrise\": \"05:49\", \"sunset\": \"20:49\"},\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "daily = [\n",
    "    [\"2024-07-08\", 63, 82, \"05:48\", \"20:50\"], # Monday\n",
    "    [\"2024-07-09\", 67, 85, \"05:49\", \"20:49\"], # Tuesday\n",
    "    [\"2024-07-10\", 66, 82, \"05:50\", \"20:48\"], # Wednesday\n",
    "    [\"2024-07-11\", 65, 83, \"05:50\", \"20:48\"], # Thursday\n",
    "    [\"2024-07-12\", 67, 86, \"05:51\", \"20:48\"], # Friday\n",
    "    ]\n",
    "\n",
    "##### YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2024-07-08': {'low': 63, 'high': 82, 'sunrise': '05:48', 'sunset': '20:50'},\n",
       " '2024-07-09': {'low': 67, 'high': 85, 'sunrise': '05:49', 'sunset': '20:49'},\n",
       " '2024-07-10': {'low': 66, 'high': 82, 'sunrise': '05:50', 'sunset': '20:48'},\n",
       " '2024-07-11': {'low': 65, 'high': 83, 'sunrise': '05:50', 'sunset': '20:48'},\n",
       " '2024-07-12': {'low': 67, 'high': 86, 'sunrise': '05:51', 'sunset': '20:48'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dtemps = {}\n",
    "\n",
    "for ll in daily:\n",
    "    dtemps[ll[0]] = {\n",
    "        \"low\": ll[1], \"high\": ll[2], \"sunrise\": ll[3], \"sunset\": ll[4]\n",
    "        }\n",
    "\n",
    "dtemps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "Save `dtemps` to your current working directory  as `dtemps.pkl`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"dtemps.pkl\", \"wb\") as fpkl:\n",
    "    pickle.dump(dtemps, fpkl, pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Two additional days of data have come in. Update your serialized dictionary to include data from 2024-07-13 and 2024-07-14, and write the updated dictionary back to file. Specifically:\n",
    "\n",
    "1. Load in *dtemps.pkl* from file. \n",
    "2. Add the additional data the same way as before.\n",
    "3. Rewrite the updated dictionary back to *dtemps.pkl*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weekend = [\n",
    "    [\"2024-07-13\", 74, 91, \"05:52\", \"20:47\"], # Saturday\n",
    "    [\"2024-07-14\", 79, 92, \"05:53\", \"20:47\"], # Sunday\n",
    "    ]\n",
    "\n",
    "##### YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"dtemps.pkl\", \"rb\") as fpkl:\n",
    "    dtemps = pickle.load(fpkl)\n",
    "\n",
    "# Add saturday and sunday. \n",
    "for ll in weekend:\n",
    "    dtemps[ll[0]] = {\n",
    "        \"low\": ll[1], \"high\": ll[2], \"sunrise\": ll[3], \"sunset\": ll[4]\n",
    "        }\n",
    "\n",
    "# Export dtemps to dtemps.pkl.\n",
    "with open(\"dtemps.pkl\", \"wb\") as fpkl:\n",
    "    pickle.dump(dtemps, fpkl, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "### **[2. hashlib](https://docs.python.org/3/library/hashlib.html#module-hashlib)**\n",
    "\n",
    "Hash functions are cryptographic one-way functions that take input data (of any size) and produce a fixed-size string of bytes, typically referred to as a hash code, hash digest or hash. \n",
    "\n",
    "\n",
    "**Hash function characteristics:**\n",
    "\n",
    "- The same input will always produce the same output.\n",
    "\n",
    "- A tiny change to the input data (like changing one bit) should change the hash so extensively that the new hash appears uncorrelated with the old hash.\n",
    "\n",
    "- It should be difficult to find two different inputs that produce the same output hash (collision resistance).\n",
    "\n",
    "<br>\n",
    "\n",
    "**Common hash functions:**\n",
    "\n",
    "- **MD5**: Once widely used, now considered insecure due to vulnerabilities allowing for collision attacks.\n",
    "- **SHA-1**: Also no longer considered secure against well-funded attackers.\n",
    "- **SHA-256** and **SHA-3**: Part of the SHA-2 and SHA-3 families, these are currently recommended for security due to their resistance to known attack methods.\n",
    "\n",
    "\n",
    "**Uses:**\n",
    "\n",
    "- Quick comparison of arbitrary objects (image comparison)\n",
    "- Data integrity\n",
    "- Storing passwords\n",
    "\n",
    " \n",
    " \n",
    "**Quick Introduction:**\n",
    "\n",
    "- [Password Hashing, Salts, Peppers](https://www.youtube.com/watch?v=--tnZMuoK3E&list=PLr4vqfPMMQf6ExJe8kPTVARhNwGs197Sq&index=8)\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Each OS will have different hashing algorithms available. To list available hashing algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blake2b',\n",
       " 'blake2s',\n",
       " 'md5',\n",
       " 'md5-sha1',\n",
       " 'ripemd160',\n",
       " 'sha1',\n",
       " 'sha224',\n",
       " 'sha256',\n",
       " 'sha384',\n",
       " 'sha3_224',\n",
       " 'sha3_256',\n",
       " 'sha3_384',\n",
       " 'sha3_512',\n",
       " 'sha512',\n",
       " 'sha512_224',\n",
       " 'sha512_256',\n",
       " 'shake_128',\n",
       " 'shake_256',\n",
       " 'sm3'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import hashlib\n",
    "\n",
    "# List available algorithms on your computer.\n",
    "hashlib.algorithms_available\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "Example creating a hash from an arbitrary string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d0b2c52076e174766898f76a3e15bc47f329f15aef3a376c2c74f53e8425706f'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# String to hash.\n",
    "s = \"Sittin' in the shade and shoveling with a spade\"\n",
    "\n",
    "# Create digest.\n",
    "digest1 = hashlib.sha256(s.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "digest1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "How does the digest change if I add a trailing space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digest1: d0b2c52076e174766898f76a3e15bc47f329f15aef3a376c2c74f53e8425706f\n",
      "digest2: f253cadd1fbf55889e1836b7b18f4d4e14d37be3b4a306cd4142bced9c726a54\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s2 = \"Sittin' in the shade and shoveling with a spade \"\n",
    "\n",
    "digest2 = hashlib.sha256(s2.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "print(f\"digest1: {digest1}\")\n",
    "print(f\"digest2: {digest2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "Digests can be created from virtually any type of file. Here is an alternate cover of the Allman Brothers classic *At Fillmore East* album:\n",
    "\n",
    "![](https://popspotsnyc.com/ALLMAN_BROTHERS_FILLMORE_EAST/allman_bros_fillmore_east.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "To create a hash from *fillmore-east.jpg* (available under Module 14 In-Class Materials in Canvas), run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'86edc04e53b51e193563aa83b9d52557e963c0f4a9ddb2c054c16b11e3b295e4'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Update your path to download directory.\n",
    "img_path = \"misc/fillmore-east.jpg\"\n",
    "\n",
    "with open(img_path, \"rb\") as f:\n",
    "    abb_digest = hashlib.sha256(f.read()).hexdigest()\n",
    "\n",
    "# Or as a one-liner:  \n",
    "# abb_digest = hashlib.sha256(open(img_path, \"rb\").read()).hexdigest()\n",
    "\n",
    "abb_digest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "Hashes are commonly used for data integrity checks. If a single byte of a file is changed, it will render a completely different digest. \n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### **Checkpoint \\#2: Data Integrity Check**\n",
    "\n",
    "On Python.org, if we navigate to the [Python 3.12.4 installer page](https://www.python.org/downloads/release/python-3124/), we see that each file has an associated MD5 checksum. Perform the following:\n",
    "\n",
    "1. Download the *Windows installer (64-bit)* or MacOS installer if not on Windows. \n",
    "\n",
    "2. Copy the provided MD5 checksum from Python.org, and save it to a variable, something like `h1`. \n",
    "\n",
    "3. Generate the appropriate hash from the donwloaded Python installer (should be no different than the example above where we created a hash from *fillmore-east.jpg*). Set this hash to another variable, `h2`. \n",
    "\n",
    "4. Verify that `h1` and `h2` are identical.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1: f3df1be26cc7cbd8252ab5632b62d740\n",
      "h2: f3df1be26cc7cbd8252ab5632b62d740\n",
      "h1==h2?: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# MD5 hash taken from Python.org.\n",
    "h1 = \"f3df1be26cc7cbd8252ab5632b62d740\" \n",
    "\n",
    "# Path to downloaded installer.\n",
    "p = \"C:\\\\Users\\\\jtriv\\\\Downloads\\\\python-3.12.4-amd64.exe\"\n",
    "\n",
    "# Create hash from downloaded installer.\n",
    "h2 = hashlib.md5(open(p, \"rb\").read()).hexdigest()\n",
    "\n",
    "print(f\"h1: {h1}\")\n",
    "print(f\"h2: {h2}\")\n",
    "print(f\"h1==h2?: {h1 == h2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "### **Checkpoint \\#3: Pickling your hashes (not a euphemism)**\n",
    "\n",
    "\n",
    "1. Identify the hashing algorithms available on your computer (should be the same for most Windows machines, may be some differences for Linux/MacOS). Choose 3, and create separate digests of the Gettysburg Address for each. \n",
    "\n",
    "2. Create a dictionary with keys the string representation of the algorithm you chose and values the digest for that algorithm. For example, if I picked sha1, sha224 and sha384, my dictionary would look like the following:\n",
    "\n",
    "```\n",
    "d = {\n",
    "    \"sha1\": \"whatever the sha1 digest turns out to be\",\n",
    "    \"sha224\": \"whatever the sha224 digest turns out to be\",\n",
    "    \"sha384\": \"whatever the sha384 digest turns out to be\"\n",
    "}\n",
    "```\n",
    "\n",
    "3. Serialize the dictionary to a .pkl file named *my-digests.pkl*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gettysburg = \"\"\"\n",
    "Four score and seven years ago our fathers brought forth on this continent, a \n",
    "new nation, conceived in Liberty, and dedicated to the proposition that all men \n",
    "are created equal. Now we are engaged in a great civil war, testing whether that \n",
    "nation, or any nation so conceived and so dedicated, can long endure. We are met \n",
    "on a great battle-field of that war. We have come to dedicate a portion of that \n",
    "field, as a final resting place for those who here gave their lives that that \n",
    "nation might live. It is altogether fitting and proper that we should do this. \n",
    "But, in a larger sense, we can not dedicate -- we can not consecrate we can not \n",
    "hallow this ground. The brave men, living and dead, who struggled here, have \n",
    "consecrated it, far above our poor power to add or detract. The world will \n",
    "little note, nor long remember what we say here, but it can never forget what \n",
    "they did here. It is for us the living, rather, to be dedicated here to the \n",
    "unfinished work which they who fought here have thus far so nobly advanced. \n",
    "It is rather for us to be here dedicated to the great task remaining before us \n",
    "that from these honored dead we take increased devotion to that cause for which \n",
    "they gave the last full measure of devotion -- that we here highly resolve that \n",
    "these dead shall not have died in vain -- that this nation, under God, shall \n",
    "have a new birth of freedom -- and that government of the people, by the people, \n",
    "for the people, shall not perish from the earth.\n",
    "\"\"\"\n",
    "\n",
    "##### YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = {\n",
    "    \"md5\": hashlib.md5(gettysburg.encode(\"utf-8\")).hexdigest(),\n",
    "    \"sha384\": hashlib.sha384(gettysburg.encode(\"utf-8\")).hexdigest(),\n",
    "    \"sha512\": hashlib.sha512(gettysburg.encode(\"utf-8\")).hexdigest(),\n",
    "}\n",
    "\n",
    "\n",
    "with open(\"my-digests.pkl\", \"wb\") as fpkl:\n",
    "    pickle.dump(d, fpkl, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "### **[3. difflib](https://docs.python.org/3/library/difflib.html#module-difflib)**\n",
    "\n",
    "\n",
    "difflib provides tools for computing and working with differences between sequences. It includes functions and classes for comparing sequences, finding differences, and generating human-readable differences or patches.\n",
    "\n",
    "\n",
    "Imagine we have two strings and want to quantify their similarity. We can leverage `difflib.SequenceMatcher`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score of s1 and s2: 90.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import difflib\n",
    "\n",
    "s1 = \"either renew oneself or perish\"\n",
    "s2 = \"either renew thyself or perish\"\n",
    "\n",
    "# Compute similarity score of s1 and s2. \n",
    "sim_score = difflib.SequenceMatcher(None, s1, s2).ratio()\n",
    "\n",
    "print(f\"Similarity score of s1 and s2: {sim_score:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### **Checkpoint \\#4: Finding Similar Addresses**\n",
    "\n",
    "For the list of addresses below, compute the similarity score of each address with `target_addr`. What are the 3 highest similarity scores and addresses when compared with `target_addr`? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_addr = \"123 Main, Springfield IL 62701\"\n",
    "\n",
    "addrs = [\n",
    "    \"456 Elm Avenue, Pleasantville, NY 10570\",\n",
    "    \"789 Oak Lane, Boulder, CO 80302\",\n",
    "    \"101 Maple Street, Portland OR 97201\", \n",
    "    \"234 Pine Bluff Road, San Francisco, CA 94103\",\n",
    "    \"123 Main Street, Springfield, IL 62701\",\n",
    "    \"567 Cedar Drive, Austin, TX 78701\",\n",
    "    \"890 Birch Court, Seattle, WA 98101\", \n",
    "    \"123 Main St., Springfield, IL 62701-7543\",\n",
    "    \"111 Spruce Street, Boston, MA 02108\",\n",
    "    \"222 Cherry Lane, Miami, FL 33101\",\n",
    "    \"333 Walnut Avenue, Denver, CO 80202\",\n",
    "    \"444 Ash Street, Nashville, TN 37201\",\n",
    "    \"555 Willow Way, Chicago, IL 60601\",\n",
    "    \"666 Magnolia Boulevard, Los Angeles, CA 90001\",\n",
    "    \"777 Cedar Lane, Atlanta, GA 30301\",\n",
    "    ]\n",
    "\n",
    "\n",
    "##### YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('123 Main Street, Springfield, IL 62701', 0.8823529411764706),\n",
       " ('123 Main St., Springfield, IL 62701-7543', 0.8571428571428571),\n",
       " ('101 Maple Street, Portland OR 97201', 0.46153846153846156)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sim_scores = []\n",
    "\n",
    "for addr in addrs:\n",
    "    sim_score = difflib.SequenceMatcher(None, addr, target_addr).ratio()\n",
    "    sim_scores.append((addr, sim_score))\n",
    "\n",
    "# Sort list in decreasing order of score.\n",
    "sim_scores = sorted(sim_scores, key=lambda v: v[1], reverse=True)\n",
    "\n",
    "sim_scores[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "### **[4. re](https://docs.python.org/3/library/re.html#module-re)**\n",
    "\n",
    "#### Regular Expressions in Python\n",
    "\n",
    "- [Regular Expressions Video](https://www.youtube.com/watch?v=r6I-Ahc0HB4&list=PL4cUxeGkcC9g6m_6Sld9Q4jzqdqHd2HiD)\n",
    "- [Python Regular Expressions HOWTO](https://docs.python.org/3/howto/regex.html)\n",
    "\n",
    "\n",
    "Regular expressions (regex) are sequences of characters used to define search patterns. They enable sophisticated string matching and manipulation in text processing tasks. Regex patterns specify sequences of characters that must be found or matched in a string. They're employed in tasks such as text search and replace, input validation, and data extraction. Refer to the [Python Regular Expression HOWTO](https://docs.python.org/3/howto/regex.html) for more information.\n",
    "\n",
    "\n",
    "- Python Regular Expression Evaluator: https://pythex.org/\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "Many of the string methods we've used are similar to regular expressions (`startswith`, `endswith`, `isalpha`), but these are relatively limited. Regular expressions can be leveraged to find complex patterns in text streams.\n",
    "\n",
    "The cheatsheet at pythex.org contains the full list of regular expression symbols, but a few are listed below:\n",
    "\n",
    "- `?` : optional (0 or 1 repetitions).  \n",
    "- `*` : Zero or more times.  \n",
    "- `+` : One or more times.     \n",
    "- `{m,n}` : Between m and n times.  \n",
    "- `^` : Match at start of string.  \n",
    "- `$` : Match at end of string.  \n",
    "- `.` : Matches any character except newline.  \n",
    "- `[A-Z]`: Matches uppercase letters.  \n",
    "- `[a-z]`: Matches lowercase letters.  \n",
    "- `[A-Za-z0-9.-]`: Matches uppercase, lowercase, digits, literal `.` and `-`.  \n",
    "- `\\b`: Matches empty string at word boundary.    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "Let's say I'm interested in extracting phone numbers from `stream`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "312-845-5555\n",
    "apples\n",
    "In 1492 columbus sailed the ocean blue\n",
    "2018-09-07\n",
    "(312)-845-5555\n",
    "17-9866758-900987757567\n",
    "\"\"\"\n",
    "\n",
    "stream = '''\n",
    "    312-845-5555\n",
    "    apples\n",
    "    In 1492 columbus sailed the ocean blue\n",
    "    2018-09-07\n",
    "    (312)-845-5555\n",
    "    17-9866758-900987757567\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will need to identify 3 numbers, followed by a dash, then 3 more numbers followed by a dash then 4 numbers followed by a dash. A first pass might be:\n",
    "\n",
    "```\n",
    "\\d{3}-\\d{3}-\\d{4}\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "When we check this in Pythex, only the first phone number is captured. We need to account for parens surrounding the area code, but only in some cases (remember the `?` matches 0 or 1 instances):\n",
    "\n",
    "```\n",
    "\\(?\\d{3}\\)?-\\d{3}-\\d{4}\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "Testing this in Pythex matches both phone numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We've created our regular expression `\"\\(?\\d{3}\\)?-\\d{3}-\\d{4}\"`. Here is how to extract the matches using the re library:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['312-845-5555', '(312)-845-5555']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "matches = re.findall(r\"\\(?\\d{3}\\)?-\\d{3}-\\d{4}\", stream)\n",
    "\n",
    "matches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### **Checkpoint \\#5: Parsing Web Logs**\n",
    "\n",
    "The *weblog.txt* file (downloadable from Module 14 In-Class Materials page in Canvas) contains over 7,000 website requests for a site in January of 2019. Each request is prefixed by an IP address. Here is a sample of the first few rows:\n",
    "\n",
    "```\n",
    "5.211.97.39 - - [22/Jan/2019:04:10:40 +0330] \"GET /m/filter/ ...\"\n",
    "5.211.97.39 - - [22/Jan/2019:04:10:40 +0330] \"GET /settings/logo HTTP/1.1 ...\"\n",
    "5.211.97.39 - - [22/Jan/2019:04:10:41 +0330] \"GET /image/58131/productModel/200x200 ...\"\n",
    "5.211.97.39 - - [22/Jan/2019:04:10:41 +0330] \"HEAD /amp_preconnect_polyfill_404 ...\"\n",
    "```\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Using regular expressions, extract all IP addresses from *weblog.txt*, and determine the number of unique addresses.\n",
    "\n",
    "IP4 addresses are 32-bit numbers, typically expressed in decimal format as four 8-bit fields separated by periods (e.g., 192.168.1.1). Each field can range from 0 to 255 (i.e., IP addresses can range from 0.0.0.0 thru 255.255.255.255).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### YOUR CODE HERE #####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique IP addresses: 470\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weblog_path = \"misc/weblog.txt\"\n",
    "\n",
    "with open(weblog_path, \"r\") as f:\n",
    "    logs = f.read()\n",
    "\n",
    "pattern = r\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\"\n",
    "\n",
    "matches = re.findall(pattern, logs)\n",
    "\n",
    "uniq_ips = list(set(matches))\n",
    "\n",
    "print(f\"Number of unique IP addresses: {len(uniq_ips):,.0f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
